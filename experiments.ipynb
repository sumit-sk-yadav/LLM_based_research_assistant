{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21bd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'data\\\\DVSTUDY_PAPER.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c449e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30f0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af42ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_all_pdfs(folder_path: str) -> list:\n",
    "    pages = []\n",
    "    pdf_files = Path(folder_path).rglob(\"*.pdf\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        loader = PyPDFLoader(str(pdf_file))\n",
    "        async for page in loader.alazy_load():\n",
    "            pages.append(page)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc8badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = await load_all_pdfs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7450a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8f7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "separators = [\n",
    "    \"\\n\\n\",              # Paragraphs\n",
    "    \"\\n\",                # New lines\n",
    "    r\"\\.\\s\",             # Sentences\n",
    "    r\"(?:Fig\\.|Table)\\s\\d+\",  # Split around figures/tables\n",
    "    r\"\\s{2,}\",           # Double spaces (used in some PDFs)\n",
    "    \" \",                 # Words\n",
    "    \"\"                   # Fallback\n",
    "]\n",
    "\n",
    "def text_splitter(pages:list[str], c_size: int, c_overlap: int) -> list:\n",
    "    chunks = []\n",
    "    if pages:\n",
    "        try:\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size = c_size, separators=separators,chunk_overlap=c_overlap)\n",
    "            chunks = splitter.split_documents(pages)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d630a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter(pages, 1000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf978287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "cleaned_chunks = [Document(page_content=clean_text(doc.page_content), metadata=doc.metadata) for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121d233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cleaned_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adaad38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# --- Embedding wrapper using thenlper/gte-base ---\n",
    "class GTEEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"thenlper/gte-small\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, show_progress_bar=True, convert_to_numpy=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, convert_to_numpy=True).tolist()\n",
    "\n",
    "\n",
    "# --- Utility: Hash documents for caching ---\n",
    "def compute_documents_hash(documents: List[Document]) -> str:\n",
    "    hasher = hashlib.sha256()\n",
    "    for doc in documents:\n",
    "        hasher.update(doc.page_content.encode(\"utf-8\"))\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "\n",
    "# --- Main function: Embed and cache ---\n",
    "def embed_and_store_once(\n",
    "    documents: List[Document],\n",
    "    persist_dir: str = \"embeddings\",\n",
    "    model_name: str = \"thenlper/gte-small\"\n",
    ") -> Chroma:\n",
    "\n",
    "    os.makedirs(persist_dir, exist_ok=True)\n",
    "    hash_path = Path(persist_dir) / \"hash.pkl\"\n",
    "    current_hash = compute_documents_hash(documents)\n",
    "\n",
    "    # Check for previously stored hash\n",
    "    if hash_path.exists():\n",
    "        with open(hash_path, \"rb\") as f:\n",
    "            saved_hash = pickle.load(f)\n",
    "        if saved_hash == current_hash:\n",
    "            print(\"ðŸŸ¢ Reusing existing ChromaDB vector store from 'embeddings/'\")\n",
    "            return Chroma(\n",
    "                persist_directory=persist_dir,\n",
    "                embedding_function=GTEEmbeddings(model_name),\n",
    "                client_settings=Settings(persist_directory=persist_dir, anonymized_telemetry=False)\n",
    "            )\n",
    "\n",
    "    # Embed and store if hash differs\n",
    "    print(\"ðŸ”µ Generating new embeddings and storing in 'embeddings/'...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=GTEEmbeddings(model_name),\n",
    "        persist_directory=persist_dir,\n",
    "        client_settings=Settings(persist_directory=persist_dir, anonymized_telemetry=False)\n",
    "    )\n",
    "\n",
    "    # Save hash for reuse\n",
    "    with open(hash_path, \"wb\") as f:\n",
    "        pickle.dump(current_hash, f)\n",
    "\n",
    "    return vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a28e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Reusing existing ChromaDB vector store from 'embeddings/'\n"
     ]
    }
   ],
   "source": [
    "vectorstore = embed_and_store_once(cleaned_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c62368d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Association index = O â€“ E Ïƒ where O is the observed co-occurrence of a species pair, E is the ex- pected co-occurrence of the pair and Ïƒ is the standard deviation of the expected co-occurrence of the species. The expected co-occurrence was calculated from randomizations on the species by flock presence absence matrix. Randomizations were set up in the following manner: Since we were interested in examining differences in flocks of different rich - ness values, we kept the number of flocks in each richness class in our expected data equal to the number of flocks in the observed data- set. The observed data matrix was randomized by holding the column totals (flock richness) constant and using the species occurrences as proportions. For each randomized matrix, we calculated a co-occur - rence value for every species pair. We performed 1000 iterations and'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Association index\"\n",
    "result = vectorstore.similarity_search(query, k=5)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c3fe9",
   "metadata": {},
   "source": [
    "# scripts/retriever.py\n",
    "\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from chromadb.config import Settings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceHub  # Or any LLM model of your choice\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# === Configuration ===\n",
    "PERSIST_DIR = os.path.join(\"embeddings\")  # Path where Chroma DB is persisted\n",
    "EMBEDDING_MODEL = \"thenlper/gte-small\"    # Pre-trained embedding model\n",
    "LLM_MODEL = \"google/flan-t5-base\"         # Or any other LLM model\n",
    "TOP_K = 5                                 # Number of top results to retrieve from vector store\n",
    "\n",
    "def load_vectorstore(persist_dir: str = PERSIST_DIR, model_name: str = EMBEDDING_MODEL):\n",
    "    \"\"\"\n",
    "    Loads the vector store from the specified directory and embedding model.\n",
    "    \"\"\"\n",
    "    embedding_function = GTEEmbeddings(model_name=model_name)\n",
    "\n",
    "    logger.info(f\"Loading vector store from {persist_dir}...\")\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_dir,\n",
    "        embedding_function=embedding_function,\n",
    "        client_settings=Settings(persist_directory=persist_dir, anonymized_telemetry=False)\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def retrieve_relevant_documents(query: str, vectorstore: Chroma, top_k: int = TOP_K):\n",
    "    \"\"\"\n",
    "    Retrieves the top K most relevant documents for the provided query from the vector store.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Retrieving top {top_k} most relevant documents for query: {query}\")\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": top_k})\n",
    "    return retriever.get_relevant_documents(query)\n",
    "\n",
    "\n",
    "def setup_llm_model(llm_model: str = LLM_MODEL):\n",
    "    \"\"\"\n",
    "    Sets up the LLM model for question answering.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Setting up LLM model: {llm_model}...\")\n",
    "    llm = HuggingFaceHub(repo_id=llm_model, model_kwargs={\"temperature\": 0.2, \"max_length\": 512})\n",
    "    return llm\n",
    "\n",
    "\n",
    "def qa_chain_setup(llm, retriever):\n",
    "    \"\"\"\n",
    "    Set up the RetrievalQA chain which will use the retriever and LLM model.\n",
    "    \"\"\"\n",
    "    logger.info(\"Setting up the RetrievalQA chain...\")\n",
    "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
    "\n",
    "\n",
    "def retrieve_and_answer(query: str):\n",
    "    \"\"\"\n",
    "    Full pipeline to retrieve relevant documents and answer the question using the LLM.\n",
    "    \"\"\"\n",
    "    # Load the vector store\n",
    "    vectorstore = load_vectorstore()\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    documents = retrieve_relevant_documents(query, vectorstore)\n",
    "\n",
    "    if not documents:\n",
    "        logger.warning(\"No relevant documents found for the query.\")\n",
    "        return \"Sorry, I couldn't find any relevant information.\"\n",
    "\n",
    "    # Set up LLM model and QA chain\n",
    "    llm = setup_llm_model()\n",
    "    qa_chain = qa_chain_setup(llm, vectorstore.as_retriever())\n",
    "\n",
    "    # Use the chain to get the answer\n",
    "    result = qa_chain(query)\n",
    "\n",
    "    # Return the result along with source documents\n",
    "    answer = result['result']\n",
    "    sources = result['source_documents']\n",
    "    \n",
    "    # Format source document output (optional)\n",
    "    source_texts = [f\"Source {i+1}: {doc.page_content[:500]}...\" for i, doc in enumerate(sources)]\n",
    "    return answer, source_texts\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What does the association index mean in network analysis?\"\n",
    "    answer= retrieve_and_answer(query)\n",
    "    \n",
    "    # Output answer and source context\n",
    "    print(\"\\nðŸ§  Answer:\", answer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48cb3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from scripts.embedding import Embedder\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def load_vectorstore(persist_dir: str = \"embeddings\", model_name:str = \"thenlper/gte-small\"):\n",
    "    embedding_fn = Embedder(model_name=model_name)\n",
    "    \n",
    "    vector_store = Chroma(persist_directory=persist_dir, embedding_function=embedding_fn,\n",
    "                            client_settings=Settings(persist_directory=persist_dir, anonymized_telemetry=False))\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def retrieve_relevant_documents(query:str, vector_store:Chroma, top_k:int = 5):\n",
    "    retriever = vector_store.as_retriever(search_kwargs = {\"k\": top_k})\n",
    "    \n",
    "    return retriever.get_relevant_documents(query=query)\n",
    "\n",
    "\n",
    "def setup_llm_model(llm_model:str = \"gemma3\"):\n",
    "    llm = OllamaLLM(model=llm_model, model_kwargs={\"temperature\": 0.2})\n",
    "\n",
    "    return llm\n",
    "\n",
    "\n",
    "def retriever_chain_setup(llm, retriever):\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type=\"stuff\"  # Or another strategy like \"map_reduce\", if needed\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieve_and_answer(query: str):\n",
    "    \n",
    "    vector_store = load_vectorstore()\n",
    "    \n",
    "    relevant_docs = retrieve_relevant_documents(query=query, vector_store=vector_store)\n",
    "    \n",
    "    llm = setup_llm_model(\"deepseek-r1\")\n",
    "    \n",
    "    qa_chain = retriever_chain_setup(llm, vector_store.as_retriever())\n",
    "    \n",
    "    result = qa_chain.invoke(query)\n",
    "    \n",
    "    answer = result['result']\n",
    "    sources = result['source_documents']\n",
    "    \n",
    "    return answer, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63b2df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, sources = retrieve_and_answer(\"what is modularity and how to calculate it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2769bc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6e0a2fe0-178c-4549-a1e2-29355960b179', metadata={'appligent': 'AppendPDF Pro 6.3 Linux 64 bit Aug 30 2019 Library 15.0.4', 'author': 'Priti Bangal, Hari Sridhar, Daizaburo Shizuka, Laura N. Vander Meiden, and Kartik Shankar', 'creationdate': '2021-12-13T12:20:46-08:00', 'creator': 'Appligent AppendPDF Pro 6.3', 'moddate': '2021-12-13T12:20:46-08:00', 'page': 9, 'page_label': '10', 'producer': 'Prince 12.5 (www.princexml.com)', 'source': 'data\\\\DVSTUDY_PAPER.pdf', 'title': 'Flock-species richness influences node importance and modularity in mixed-species flock networks', 'total_pages': 24}, page_content='We use unweighted networks for filtered associations. Hence, we use degree centrality as a measure of structural importance in this analysis. Therefore, there are multiple species with the same central- ity values in this category. Calculating modularity We ran a â€˜community detection algorithmâ€™ based on the Louvian method on the networks built using the meth - ods described above. Clusters of closely connected nodes (often termed â€˜communitiesâ€™ in network parlance) were detected based on modular- ity optimization (Newman 2006). Modularity is the measure of sepa- ration between two clusters calculated based on the number of edges within versus across clusters. In this method, each vertex is assigned to a unique cluster and a modularity score is calculated. At each step, the vertices are reassigned to clusters and a network structure that gives the maximum modularity is calculated. This process is repeated until modularity cannot be increased further.'),\n",
       " Document(id='48b2f88b-ce0e-430a-8dba-4966c09656b6', metadata={'appligent': 'AppendPDF Pro 6.3 Linux 64 bit Aug 30 2019 Library 15.0.4', 'author': 'Priti Bangal, Hari Sridhar, Daizaburo Shizuka, Laura N. Vander Meiden, and Kartik Shankar', 'creationdate': '2021-12-13T12:20:46-08:00', 'creator': 'Appligent AppendPDF Pro 6.3', 'moddate': '2021-12-13T12:20:46-08:00', 'page': 9, 'page_label': '10', 'producer': 'Prince 12.5 (www.princexml.com)', 'source': 'data\\\\DVSTUDY_PAPER.pdf', 'title': 'Flock-species richness influences node importance and modularity in mixed-species flock networks', 'total_pages': 24}, page_content='until modularity cannot be increased further. Comparing the structure of species associations across flock- richness using assortativity We measured how closely the modu - lar structure of larger networks reflected the patterns of associations in 2-species flocks. We reason that species associations in 2-species'),\n",
       " Document(id='cc1d1584-e39f-49f3-bda3-480b9956294b', metadata={'appligent': 'AppendPDF Pro 6.3 Linux 64 bit Aug 30 2019 Library 15.0.4', 'author': 'Priti Bangal, Hari Sridhar, Daizaburo Shizuka, Laura N. Vander Meiden, and Kartik Shankar', 'creationdate': '2021-12-13T12:20:46-08:00', 'creator': 'Appligent AppendPDF Pro 6.3', 'moddate': '2021-12-13T12:20:46-08:00', 'page': 9, 'page_label': '10', 'producer': 'Prince 12.5 (www.princexml.com)', 'source': 'data\\\\DVSTUDY_PAPER.pdf', 'title': 'Flock-species richness influences node importance and modularity in mixed-species flock networks', 'total_pages': 24}, page_content='Bangal et al. in Oecologia (2021) 9 whole species by flock matrix and each matrix was filtered into the corresponding flock-richness subsets to calculate the association in - dex for species pairs in every flock-richness category. Network measures Weighted degree We used weighted degree, which is a commonly used measure of centrality in networks as the measure of species structural importance in flocks. Weighted degree is a node-based mea- sure which is the sum of weights of all edges that pass through the node under consideration. n WD = âˆ‘ Wi i=1 Here, WD is the weighted degree of the node also referred to as node strength, W is the edge weight and i is the number of edges that pass through the node for which weighted degree is being calculated.'),\n",
       " Document(id='2310bfba-ec15-4c8f-af6f-b5529d2a41fb', metadata={'appligent': 'AppendPDF Pro 6.3 Linux 64 bit Aug 30 2019 Library 15.0.4', 'author': 'Priti Bangal, Hari Sridhar, Daizaburo Shizuka, Laura N. Vander Meiden, and Kartik Shankar', 'creationdate': '2021-12-13T12:20:46-08:00', 'creator': 'Appligent AppendPDF Pro 6.3', 'moddate': '2021-12-13T12:20:46-08:00', 'page': 0, 'page_label': '1', 'producer': 'Prince 12.5 (www.princexml.com)', 'source': 'data\\\\DVSTUDY_PAPER.pdf', 'title': 'Flock-species richness influences node importance and modularity in mixed-species flock networks', 'total_pages': 24}, page_content='Part of the Ecology and Evolutionary Biology Commons Bangal, Priti; Sridhar, Hari; Shizuka, Daizaburo; Vander Meiden, Laura N.; and Shankar, Kartik, \"Flock- species richness influences node importance and modularity in mixed-species flock networks\" (2021). Papers in Behavior and Biological Sciences. 85. https://digitalcommons.unl.edu/bioscibehavior/85 This Article is brought to you for free and open access by the Papers in the Biological Sciences at DigitalCommons@University of Nebraska - Lincoln. It has been accepted for inclusion in Papers in Behavior and Biological Sciences by an authorized administrator of DigitalCommons@University of Nebraska - Lincoln.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f54a49b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I\\'m trying to figure out what modularity means and how to calculate it. From the context provided, it seems like modularity has something to do with network analysis, particularly in ecology where they study species associations.\\n\\nFirst, I remember that networks are made up of nodes (which could be species here) connected by edges (which represent interactions between species). The term \"modularity\" comes up when discussing community detection algorithms. The Louvian method is mentioned, which optimizes modularity to find communities or clusters in the network.\\n\\nSo, modularity measures how well a network can be divided into these communities. It\\'s like checking if within each group (community), there are more connections between species from that group than would be expected by chance. The higher the modularity score, the better separated the groups are from each other.\\n\\nNow, to calculate modularity: I think it involves comparing the actual number of edges in a network to what you\\'d expect if the nodes were connected randomly but still within their own communities. \\n\\nLooking at the formula for modularity (Q), it\\'s Q = sum over all communities (sum of edges within community minus expected edges). The expected edges are calculated based on the total number of possible connections and the density of each node in its community.\\n\\nWait, but from the context provided, they mention that modularity is optimized through a process where nodes are reassigned to clusters until no further increase is possible. So perhaps the calculation involves iteratively improving the partitioning of the network into modules (communities) by maximizing Q.\\n\\nI\\'m also trying to recall if there\\'s a standard formula for modularity beyond just the concept. Yes, the most common formula I know is Q = 1/(2m) * sum over communities [sum(edges in community) - sum(expected edges)], where m is the total number of edges.\\n\\nBut the context mentions that modularity is calculated based on the number of edges within versus across clusters. So each time you have a network, you calculate how many edges are inside the same cluster compared to what would be expected if edges were placed randomly but nodes stayed in their clusters.\\n\\nI think it\\'s important because when building these networks from species associations, higher modularity means that the structure reflects real communities where species within a community interact more with each other than with others. This helps in understanding which species are structurally important and how different groups of species form cohesive units.\\n\\nSo putting this together: Modularity is calculated by comparing the actual number of edges within each cluster to the expected number if there were no structure, then summing these differences across all clusters and normalizing by the total possible edges. The goal is to maximize Q through algorithms like the Louvian method.\\n</think>\\n\\n**Modularity in Network Analysis: A Structured Explanation**\\n\\n1. **Definition of Modularity**:  \\n   Modularity refers to the extent to which a network can be divided into distinct, cohesive groups or communities (clusters) where nodes within the same community are more densely connected than with those in different communities.\\n\\n2. **Purpose of Calculating Modularity**:  \\n   It helps assess how well the network reflects real-world groupings by measuring if edges within a cluster are significantly more numerous than would be expected by chance, indicating strong internal connections and weaker external ones.\\n\\n3. **Calculation Formula**:  \\n   The modularity (Q) is calculated using the formula:\\n   \\\\[\\n   Q = \\\\frac{1}{2m} \\\\sum_{c=1}^{k} [e_c - a_c]\\n   \\\\]\\n   Where:\\n   - \\\\( m \\\\) is the total number of edges in the network.\\n   - \\\\( e_c \\\\) is the number of edges within community \\\\( c \\\\).\\n   - \\\\( a_c \\\\) is the expected number of edges within community \\\\( c \\\\), calculated as:\\n     \\\\[\\n     a_c = \\\\frac{(k_c)(k_c - 1)}{2m}\\n     \\\\]\\n     Here, \\\\( k_c \\\\) is the sum of weights (degrees) of nodes in community \\\\( c \\\\).\\n\\n4. **Process of Calculation**:  \\n   Modularity optimization involves iteratively reassigning nodes to clusters to maximize Q using algorithms like the Louvian method. This process aims to enhance the separation between clusters until no further improvement is possible.\\n\\n5. **Interpretation of Modularity Score (Q)**:  \\n   A higher Q value indicates a stronger community structure, with edges predominantly within communities and fewer across them. This reflects coherent groupings in the network.\\n\\n6. **Significance in Species Networks**:  \\n   In ecological studies, modularity aids in understanding how species form cohesive groups or flocks, helping identify key structural nodes (species) that are crucial for maintaining these groups\\' integrity.\\n\\nIn summary, modularity is a measure of how well a network can be divided into meaningful communities based on interaction patterns, calculated by comparing actual intra-cluster edges to expected ones under random distribution.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
